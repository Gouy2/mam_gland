{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "\n",
    "from module.load_data import load_dcm, load_nii \n",
    "\n",
    "def load_jpg(jpg_path, target_size=(224, 224)):\n",
    "    # 加载 DICOM 图像\n",
    "    jpg_image = cv2.imread(jpg_path, cv2.IMREAD_GRAYSCALE)\n",
    "    jpg_image = jpg_image.astype(np.float32)\n",
    "\n",
    "    jpg_image_normalized = (jpg_image - np.min(jpg_image)) / (np.max(jpg_image) - np.min(jpg_image))  \n",
    "\n",
    "    jpg_image = exposure.equalize_adapthist(jpg_image_normalized, clip_limit=0.05)\n",
    "\n",
    "\n",
    "    return jpg_image\n",
    "\n",
    "# 遍历病人的姓名，找到对应的文件夹并加载图像\n",
    "def process_images_for_patients(base_path, target_size=(224, 224)):\n",
    "\n",
    "    # 获取所有病人文件夹\n",
    "    all_folders = sorted([f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))])\n",
    "\n",
    "    # 按病人分组文件夹，每两个文件夹为一个病人\n",
    "    patient_folders = []\n",
    "    for i in range(0, len(all_folders), 2):\n",
    "        if i + 1 < len(all_folders):\n",
    "            patient_folders.append([all_folders[i], all_folders[i + 1]])\n",
    "\n",
    "\n",
    "    # for _, row in labels_df.iterrows():\n",
    "    #     label = row['N分期']  # 获取病人标签（N分期）\n",
    "        \n",
    "    # 加载每个文件夹中的图像\n",
    "    patient_images = []\n",
    "\n",
    "    for folder_pair in patient_folders:\n",
    "        all_images = []\n",
    "        for folder in folder_pair:\n",
    "            dcm_file = None\n",
    "            nii_file = None\n",
    "            jpg_file = None\n",
    "\n",
    "            # print(folder)\n",
    "\n",
    "            # 查找对应的 .dcm 和 .nii 文件\n",
    "            for file in os.listdir(os.path.join(base_path, folder)):\n",
    "                if file.endswith('.dcm'):\n",
    "                    dcm_file = os.path.join(base_path, folder, file)\n",
    "                elif file.endswith('.nii.gz'):\n",
    "                    nii_file = os.path.join(base_path, folder, file)\n",
    "                elif file.endswith('.jpg'):\n",
    "                    jpg_file = os.path.join(base_path, folder, file)\n",
    "                           \n",
    "            # print(f\"dcm_file: {dcm_file}, nii_file: {nii_file}\")\n",
    "\n",
    "            if dcm_file and nii_file:\n",
    "                # 读取并处理 .dcm 和 .nii 图像\n",
    "                dcm_image = load_dcm(dcm_file)\n",
    "                nii_mask , top_left, bottom_right = load_nii(nii_file)\n",
    "\n",
    "                dcm_image = dcm_image[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]]\n",
    "\n",
    "                # 将两个图像相乘\n",
    "                focused_image = dcm_image * nii_mask\n",
    "\n",
    "                focused_image = cv2.resize(focused_image, target_size)\n",
    "                all_images.append(focused_image)\n",
    "            \n",
    "            elif jpg_file and nii_file:\n",
    "                # print(f\"folder {folder} jpg\")\n",
    "                jpg_image = load_jpg(jpg_file, target_size)\n",
    "                nii_mask , top_left, bottom_right = load_nii(nii_file)\n",
    "\n",
    "                jpg_image = jpg_image[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]]\n",
    "\n",
    "                focused_jpg_image = jpg_image * nii_mask\n",
    "\n",
    "                focused_jpg_image = cv2.resize(focused_jpg_image, target_size)\n",
    "                \n",
    "                all_images.append(focused_jpg_image)\n",
    "\n",
    "            elif dcm_file:\n",
    "                # print(f\"folder {folder} no nii\")\n",
    "                dcm_image = load_dcm(dcm_file)\n",
    "                dcm_image = cv2.resize(dcm_image, target_size)\n",
    "                all_images.append(dcm_image)\n",
    "\n",
    "                        \n",
    "        if len(all_images) == 2:  # 确保每个病人有 2 张图像\n",
    "\n",
    "            # print(all_images[0].shape)\n",
    "            # 将两个图像堆叠在一起\n",
    "            patient_input = np.stack(all_images, axis=0)  # 形状为 (2, 512, 512)\n",
    "            # 追加至列表中\n",
    "            patient_images.append(patient_input)\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping patient {folder_pair} due to missing images\")\n",
    "\n",
    "    return patient_images\n",
    "\n",
    "base_path = './data/chaoyang_qianzhan_190'  # 图像数据的根目录\n",
    "target_size = (224, 224)  # 目标图像尺寸\n",
    "patient_images = process_images_for_patients(base_path, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.load_data import cache_dataset\n",
    "\n",
    "test_cache_path = 'cache/test.npy'\n",
    "cache_dataset(patient_images, test_cache_path, format='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from module.load_data import load_cached_dataset,create_imgWithLabels\n",
    "\n",
    "test_cache_path = 'cache/test.npy'\n",
    "patient_images = load_cached_dataset(test_cache_path, format='npy')\n",
    "excel_path = './data/beiyou_excel/chaoyang_qianzhan_190.xlsx'  # 包含病人姓名和标签的Excel文件路径\n",
    "labels_df = pd.read_excel(excel_path)\n",
    "\n",
    "images_with_labels = create_imgWithLabels(patient_images , labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from module.dataset import ImageDataset\n",
    "\n",
    "# 测试数据预处理，与验证集一致\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Normalize([0.5, 0.5], [0.5, 0.5]),  # 标准化\n",
    "])\n",
    "\n",
    "# 创建测试数据集\n",
    "test_dataset = ImageDataset(images_with_labels, transform=test_transform)\n",
    "\n",
    "# 创建测试数据加载器\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "测试集准确率: 0.5000\n",
      "测试集 AUC 值: 0.5103\n"
     ]
    }
   ],
   "source": [
    "import module.model\n",
    "import importlib\n",
    "importlib.reload(module.model)\n",
    "\n",
    "from module.model import Resnet18_cbam\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def model_test(model, model_path, device = None):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"使用设备: {device}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path,weights_only=True))\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "\n",
    "    # 初始化变量\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 数据移动到设备\n",
    "\n",
    "            outputs = model(inputs)  # 模型推理\n",
    "            probs = F.softmax(outputs, dim=1)  # 计算每个类别的概率\n",
    "            _, predicted = torch.max(outputs, 1)  # 获取预测结果\n",
    "\n",
    "            # predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            # correct += (predicted.view(-1) == labels).sum().item()  \n",
    "\n",
    "            # 统计正确数和总数\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # 收集所有标签和概率\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = correct / total\n",
    "    print(f\"测试集准确率: {accuracy:.4f}\")\n",
    "\n",
    "    # 计算 AUC\n",
    "    all_labels = np.concatenate(all_labels)  # 合并所有批次标签\n",
    "    all_probs = np.concatenate(all_probs)    # 合并所有批次概率\n",
    "\n",
    "    # 使用正类的概率（假设正类为索引1）\n",
    "    positive_probs = all_probs[:, 1]\n",
    "\n",
    "    # 计算每个类别的 AUC\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, positive_probs)\n",
    "        print(f\"测试集 AUC 值: {auc:.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"AUC 计算失败: {e}\")\n",
    "        \n",
    "\n",
    "model = Resnet18_cbam(num_classes=2)\n",
    "model_path = './model_save/best_auc_1_25.pth'\n",
    "model_test(model,model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
