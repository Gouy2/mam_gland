{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from load_img import load_dcm, load_nii \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def load_jpg(jpg_path, target_size=(512, 512)):\n",
    "    # 加载 DICOM 图像\n",
    "    jpg_image = cv2.imread(jpg_path, cv2.IMREAD_GRAYSCALE)\n",
    "    jpg_image = jpg_image.astype(np.float32)\n",
    "\n",
    "    jpg_image_normalized = (jpg_image - np.min(jpg_image)) / (np.max(jpg_image) - np.min(jpg_image))  \n",
    "\n",
    "    # 转换尺寸（512x512）\n",
    "    jpg_image_resized = cv2.resize(jpg_image_normalized, target_size)\n",
    "\n",
    "\n",
    "    return jpg_image_resized\n",
    "\n",
    "# 遍历病人的姓名，找到对应的文件夹并加载图像\n",
    "def process_images_for_patients(base_path, target_size=(512, 512)):\n",
    "\n",
    "    # 获取所有病人文件夹\n",
    "    all_folders = sorted([f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))])\n",
    "\n",
    "    # 按病人分组文件夹，每两个文件夹为一个病人\n",
    "    patient_folders = []\n",
    "    for i in range(0, len(all_folders), 2):\n",
    "        if i + 1 < len(all_folders):\n",
    "            patient_folders.append([all_folders[i], all_folders[i + 1]])\n",
    "\n",
    "\n",
    "    # for _, row in labels_df.iterrows():\n",
    "    #     label = row['N分期']  # 获取病人标签（N分期）\n",
    "        \n",
    "    # 加载每个文件夹中的图像\n",
    "    patient_images = []\n",
    "\n",
    "    for folder_pair in patient_folders:\n",
    "        all_images = []\n",
    "        for folder in folder_pair:\n",
    "            dcm_file = None\n",
    "            nii_file = None\n",
    "            jpg_file = None\n",
    "\n",
    "            # print(folder)\n",
    "\n",
    "            # 查找对应的 .dcm 和 .nii 文件\n",
    "            for file in os.listdir(os.path.join(base_path, folder)):\n",
    "                if file.endswith('.dcm'):\n",
    "                    dcm_file = os.path.join(base_path, folder, file)\n",
    "                elif file.endswith('.nii.gz'):\n",
    "                    nii_file = os.path.join(base_path, folder, file)\n",
    "                elif file.endswith('.jpg'):\n",
    "                    jpg_file = os.path.join(base_path, folder, file)\n",
    "                           \n",
    "            # print(f\"dcm_file: {dcm_file}, nii_file: {nii_file}\")\n",
    "\n",
    "            if dcm_file and nii_file:\n",
    "                # 读取并处理 .dcm 和 .nii 图像\n",
    "                dcm_image = load_dcm(dcm_file, target_size)\n",
    "                nii_mask = load_nii(nii_file, target_size)\n",
    "\n",
    "                # 将两个图像相乘\n",
    "                focused_dcm_image = dcm_image * nii_mask\n",
    "                all_images.append(focused_dcm_image)\n",
    "            \n",
    "            elif jpg_file and nii_file:\n",
    "                # print(f\"folder {folder} jpg\")\n",
    "                jpg_image = load_jpg(jpg_file, target_size)\n",
    "                nii_mask = load_nii(nii_file, target_size)\n",
    "\n",
    "                # 将两个图像相乘\n",
    "                focused_jpg_image = jpg_image * nii_mask\n",
    "                all_images.append(focused_jpg_image)\n",
    "\n",
    "            elif dcm_file:\n",
    "                # print(f\"folder {folder} no nii\")\n",
    "                all_images.append(load_dcm(dcm_file, target_size))\n",
    "                        \n",
    "        if len(all_images) == 2:  # 确保每个病人有 2 张图像\n",
    "\n",
    "            # print(all_images[0].shape)\n",
    "            # 将两个图像堆叠在一起\n",
    "            patient_input = np.stack(all_images, axis=0)  # 形状为 (2, 512, 512)\n",
    "            # 追加至列表中\n",
    "            patient_images.append(patient_input)\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping patient {folder_pair} due to missing images\")\n",
    "\n",
    "    return patient_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\mg\\lib\\site-packages\\pydicom\\charset.py:754: UserWarning: Unknown encoding 'ISO 2022 IR 165' - using default encoding instead\n",
      "  _warn_about_invalid_encoding(encoding)\n"
     ]
    }
   ],
   "source": [
    "# from process_data import process_images_for_patients\n",
    "\n",
    "base_path = './chaoyang_qianzhan_190'  # 图像数据的根目录\n",
    "\n",
    "target_size = (512, 512)  # 目标图像尺寸\n",
    "\n",
    "patient_images = process_images_for_patients(base_path, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_labels(excel_path):\n",
    "    labels_df = pd.read_excel(excel_path)\n",
    "    return labels_df\n",
    "\n",
    "excel_path = './beiyou_excel/chaoyang_prospective_190.xlsx'  # 包含病人姓名和标签的Excel文件路径\n",
    "labels_df = load_labels(excel_path)\n",
    "# 补全标签并构建 images_with_labels 列表\n",
    "images_with_labels = []\n",
    "for i, patient_input in enumerate(patient_images):\n",
    "    label = labels_df.iloc[i]['N分期']  # 按顺序获取对应的标签\n",
    "\n",
    "    # 如果标签为 NaN，则用均值填充\n",
    "    if pd.isna(label):\n",
    "        label = 1.0\n",
    "\n",
    "    images_with_labels.append((patient_input, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import ImageDataset\n",
    "\n",
    "# 测试数据预处理，与验证集一致\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Normalize([0.5], [0.5]),  # 标准化\n",
    "])\n",
    "\n",
    "# 创建测试数据集\n",
    "test_dataset = ImageDataset(images_with_labels, transform=test_transform)\n",
    "\n",
    "# 创建测试数据加载器\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\mg\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\mg\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\YetGirt\\AppData\\Local\\Temp\\ipykernel_10588\\1640447935.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "测试集准确率: 0.5000\n",
      "测试集 AUC 值: 0.5678\n"
     ]
    }
   ],
   "source": [
    "from model import Resnet18_cbam\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = Resnet18_cbam(num_classes=4)\n",
    "model_path = './epoch100_model.pth'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "\n",
    "# 初始化变量\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 数据移动到设备\n",
    "\n",
    "        outputs = model(inputs)  # 模型推理\n",
    "        probs = F.softmax(outputs, dim=1)  # 计算每个类别的概率\n",
    "        _, predicted = torch.max(outputs, 1)  # 获取预测结果\n",
    "\n",
    "        # 统计正确数和总数\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # 收集所有标签和概率\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = correct / total\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")\n",
    "\n",
    "# 计算 AUC\n",
    "all_labels = np.concatenate(all_labels)  # 合并所有批次标签\n",
    "all_probs = np.concatenate(all_probs)    # 合并所有批次概率\n",
    "\n",
    "# 计算每个类别的 AUC\n",
    "try:\n",
    "    auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
    "    print(f\"测试集 AUC 值: {auc:.4f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"AUC 计算失败: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
